# Update these with your Supabase details from your project settings > API
# https://app.supabase.com/project/_/settings/api
NEXT_PUBLIC_SUPABASE_URL=your-project-url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-publishable-or-anon-key

# LLM Provider Configuration
# Supported providers: ollama | openai
# REQUIRED: Set to your desired provider
LLM_PROVIDER=ollama

# Ollama Configuration (when LLM_PROVIDER=ollama)
# OLLAMA_HOST is optional - defaults to http://localhost:11434 if not set
OLLAMA_HOST=http://localhost:11434
OUTLINE_VALIDATION_MODEL=llama3.1
CODE_GENERATION_MODEL=llama3.1

# JSX Generation Model Recommendation
# For optimal JSX/React code generation, use deepseek-coder-v2:
# Run: ollama pull deepseek-coder-v2
# Then set: CODE_GENERATION_MODEL=deepseek-coder-v2:latest
#
# Alternative coding models:
# - qwen2.5-coder:32b (excellent for code generation)
# - codellama:34b (Meta's premier coding model)
# - yi-coder (specialized for web development)

# OpenAI Configuration (when LLM_PROVIDER=openai)
# REQUIRED when using OpenAI provider:
# OPENAI_API_KEY=sk-...
#
# OPTIONAL - Custom endpoint (for Vercel AI Gateway, Azure OpenAI, etc.):
# OPENAI_BASE_URL=https://gateway.vercel.app
#
# Example for Vercel AI Gateway:
# LLM_PROVIDER=openai
# OPENAI_API_KEY=sk-...
# OPENAI_BASE_URL=https://gateway.vercel.app
# OUTLINE_VALIDATION_MODEL=gpt-4o
# CODE_GENERATION_MODEL=gpt-4o
